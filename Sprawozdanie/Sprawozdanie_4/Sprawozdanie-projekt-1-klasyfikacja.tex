\documentclass{classrep}
\usepackage[utf8]{inputenc}
\usepackage{color}
\usepackage{makecell}
\usepackage{graphicx}
\usepackage{url}
\usepackage{hyperref}

\studycycle{Informatyka, studia STACJONARNE, I st.}
\coursesemester{VI}

\coursename{Komputerowe systemy rozpoznawania}
\courseyear{2020/2021}

\courseteacher{prof. dr hab. inż. Adam Niewiadomski}
\coursegroup{poniedziałek, 12:00}

\author{
  \studentinfo{Julia Szymańska}{224441} \and
  \studentinfo{Przemysław Zdrzalik}{224466} }

\title{Projekt 1. Klasyfikacja dokumentów tekstowych}
\usepackage{multirow}
\begin{document}
\maketitle


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Cel projektu}

Celem projektu jest stworzenie aplikacji klasyfikującej zadany zbiór danych tekstowych metodą K najbliższych sąsiadów (k-NN). Aplikacja ma za zadanie dokonać ekstrakcji cech na zbiorach tekstów\cite{dane} oraz następnie dokonać ich klasyfikacji.\\


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Klasyfikacja nadzorowana metodą $k$-NN}

Metoda K najbliższych sąsiadów, w skrócie metoda $k$-NN\cite{dane}, jest to algorytm stosowany do klasyfikacji, który nie wymaga etapu uczenia. 
Polega na zaklasyfikowaniu rozpatrywanego elementu do grupy ze zbioru uczącego, gdzie spośród k najbliższych rozpatrywanemu elementowi sąsiadów najwięcej z nich należy do tej grupy. Klasyfikator przyjmuje cztery parametry wejściowe takie jak: warotść k - liczba rozpatrywanych sąsiadów, proporcje podziału zbiorów na zbior uczący i zbiór testowy, zbiór cech, a także metrykę i/lub miarę prawdopodobieństwa. Wynikiem klasyfikacji jest zaklasyfikowanie elementu do jednego ze zbiorów uczących. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Ekstrakcja cech, wektory cech}

Na zbiorach danych tekstowych należy dokonać ekstrakcji cech, które będą wartościami rzeczywistymi oraz tekstowymi. Dane cechy będą reprezentowały tekst w postaci wektora cech podczas procesu klasyfikacji. Przed dokonaniem ekstrakcji cech, z tekstów usuwane są słowa znajdujące się na stop liście. Teksty ze zbioru danych tekstowych posiadają strukturę: \begin{equation}
  \begin{array}{l}
  <TEXT> \\
\;\;\;\; <TITLE/>\\
\;\;\;\; <AUTHOR/>\\
\;\;\;\; <DATELINE/>\\
 \;\;\;\;<BODY/> \\
</TEXT>
  \end{array}
\end{equation}\\
\begin{enumerate}
  \item Liczba słów - cecha ta oznacza liczbę słów które składają się na pobrany tekst. Cecha ta będzie charakteryzowała długość dokumentu w postaci liczby całkowitej \begin{equation}  c_1 = len \end{equation} gdzie len - liczba słów w tekście.\\
 
 
 \item Data z tagu  \textless Dateline\textgreater\ - Każdy tekst w swoim body posiada tag \textless Dateline\textgreater , w którym znajduje się miasto oraz data podana w postaci miesiąca i dnia. Data będzie konwertowana na wartość liczbową, gdzie liczbą tą będzie numer podanego dnia w ciągu roku, licząc rok tak jakby rok był rokiem przestępnym, przykładowo data 1 marca będzie reprezentowana poprzez wartość 61. Cechę traktujemy jako cechę w postaci liczby całkowitej. Wartość będzie oznaczana poprzez symbol  c\textsubscript{3}.    \\
  \item Lokacja z tagu \textless Dateline\textgreater - jak wyżej. Lokację traktujemy jako cechę tekstową. Wartość będzie oznaczana poprzez symbol  c\textsubscript{4}. \\
  \item Tytuł z tagu \textless Title\textgreater - Każdy tekst w swoim body posiada tag \textless Title\textgreater. Tytuł traktujemy jako cechę tekstową. Wartość będzie oznaczana poprzez symbol  c\textsubscript{5}.\\
  \item Autor z tagu \textless Author\textgreater - Większość tekstów w swoim body posiada tag \textless Author\textgreater. Autora traktujemy jako cechę tekstową. Wartość będzie oznaczana poprzez symbol  c\textsubscript{6}.\\
  \item Najczęściej występująca nazwa kraju - wybieramy najczęściej występującą w analizowanym tekście nazwę kraju. Nazwy krajów pobieramy z dołączonego pliku all-places-strings.lc, przykładowo krajem występującym w pliku jest 'albania'.Nazwę kraju traktujemy jako cechę tekstową.Wartość będzie oznaczana poprzez symbol  c\textsubscript{7}.\\
  \item Zbiór występujących słów kluczowych. Za słowa kluczowe przyjmujemy słowa znajdujące się w dołączonych plikach o rozszerzeniach .lc.txt. Cechę traktujemy jako cechę tekstową.  \begin{equation}  c_8 : c_8 \in N \cap t \end{equation} gdzie N - zbiór wszystkich słów kluczowych, t - zbiór słów należących do tekstu\\
  \item Liczba wystąpień słów kluczowych - traktujemy jako cechę w postaci liczby całkowitej.\begin{equation}  c_9 = | c_8 | \end{equation} gdzie c\textsubscript{8} - zbiór występujących słów kluczowych\\
  \item Nasycenie tekstu ilością słów kluczowych - traktujemy jako cechę w postaci liczby zmienno przecinkowej.  \begin{equation} c_{10} = c_9 / c_1 \end{equation}  gdzie c\textsubscript{9} - liczba wystąpień słów kluczowych w tekscie, c\textsubscript{1} - liczba słów w tekście\\
  \item Najczęściej występujące słowo kluczowe - wybieramy najczęściej występujące w analizowanym tekście słowo kluczowe. Cechę traktujemy jako cechę tekstową. Wartość będzie oznaczana poprzez symbol  c\textsubscript{11}.\\
  \item Liczba unikatowych słów - zliczamy liczbę unikatowych słów, to znaczy występujących dokładnie raz w analizowanym tekście. Cechę traktujemy jako cechę w postaci liczby całkowitej. Wartość będzie oznaczana poprzez symbol  c\textsubscript{12}.\\
\end{enumerate}

\ \\ \\
Wektor cech będzie reprezentowany w postaci: 

\begin{equation} w = [c_1, c_2, c_3, c_4, c_5, c_6, c_7, c_8, c_9, c_{10}, c_{11}] \end{equation}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Miary jakości klasyfikacji} 

W celu określenia jakości wykonanej klasyfikacji korzystamy z czterech miar jakości klasyfikacji. Aby obliczyć każdą z miar tworzymy tablicę pomyłek, inaczej macierz błędu \cite{tablica}. Tablica składa się z dwóch wierszy i dwóch kolumn, gdzie wiersze to klasy predykowane, a kolumny to klasy rzeczywiste. Dane oznaczone jako dane pozytywne i negatywne poddawane są klasyfikacji, która przypisuje im predykowaną klasę pozytywną bądź negatywną.\\

\begin{table}[h!]
\begin{tabular}{l|l|c|c|c}
\multicolumn{2}{c}{}&\multicolumn{2}{c}{Klasa rzeczywista}&\\
\cline{3-4}
\multicolumn{2}{c|}{}&Pozytywna&Negatywna&\multicolumn{1}{c}{}\\
\cline{2-4}
\multirow{2}{*}{\thead{Klasa\\ predykowana} }& Pozytywna&  \thead{prawdziwie\\ pozytywna (TP)}
 & \thead{fałszywie\\ pozytywna (FP)} \\
\cline{2-4}
& Negatywna & \thead{fałszywie\\ negatywna (FN)} & \thead{prawdziwie\\ negatywna (TN)} \\
\cline{2-4}
\end{tabular}
 \caption{Wzór tablicy pomyłek\cite{tablica}.}
\end{table}

We wzorach zostały użyte oznaczenia:
\begin{itemize}
\item TP - liczba poprawnie zaklasyfikowanych tekstów rozpatrywanej klasy 
\item TN - liczba poprawnie zaklasyfikowanych tekstów pozostałych klas
\item FP - liczba tekstów pozostałych klas zaklasyfikowanych do rozpatrywanej klasy
\item FN - liczba tekstów rozpatrywanej klasy zaklasyfikowanych do pozostałych klas
\end{itemize}

\ \\ \\ 
Stosowane miary jakości klasyfikacji:\\
\begin{itemize}
  \item Dokładność (ang. accuracy), ACC  - jest to stosunek poprawnie zaklasyfikowanych tekstów do wszystkich klasyfikowanych tekstów.
 \begin{equation}ACC = \frac{TP + TN}{TP + TN + FP + FN} \end{equation}
 \item Precyzja (ang. precision), PPV  - jest to stopień zgodności wyników uzyskanych w określonych warunkach z wielokrotnych pomiarów. Precyzja to stosunek liczby poprawnie zaklasyfikowanych tekstów rozpatrywanej klasy do liczby wszystkich tekstów zaklasyfikowanych do rozpatrywanej klasy. 
\begin{equation} PPV =  \frac{TP} {TP+FP} \end{equation} 
Dla całego zbioru dokumentów wartość miary jest liczona jako średnia ważona obliczonych precyzji dla pojedyńczych klas, gdzie wagą jest stosunek liczebności tej klasy do liczebności wszystkich klas. 
\begin{equation} PPV_{calk} = \sum_{n=1}^{m} (PPV_n *\frac{k_n}{k}) \end{equation}
Gdzie PPV\textsubscript{calk} - precyzja obliczona dla wszystkich klas klasyfikowanych dokumentów,  m - liczba rozpatrywanych klas, PPV\textsubscript{n} - precyzja dla n-tej klasy, 
 k\textsubscript{n} - liczebność rzeczywista dokumentów klasy n, k - liczebność wszystkich klasyfikowanych dokumentów\\
\item Czułość (ang. recall), TPR  - jest to stosunek liczby poprawnie zaklasyfikowanych tekstów do rozpatrywanej klasy do liczby tekstów z rozpatrywanej klasy. 
 \begin{equation}   TPR = \frac{TP}{TP + FN} \end{equation}
Dla całego zbioru dokumentów wartość miary jest liczona jako średnia ważona obliczonych czułości dla pojedyńczych klas, gdzie wagą jest stosunek liczebności tej klasy do liczebności wszystkich klas. 
\begin{equation} TPR_{calk} = \sum_{n=1}^{m} (TPR_n *\frac{k_n}{k}) \end{equation}
Gdzie TPR\textsubscript{calk} - czułość obliczona dla wszystkich klas klasyfikowanych dokumentów,  m - liczba rozpatrywanych klas, TPR\textsubscript{n} - czułość dla n-tej klasy,  k\textsubscript{n} - liczebność rzeczywista dokumentów klasy n, k - liczebność wszystkich klasyfikowanych dokumentów\\
\item Miara F1 - średnia harmoniczna miar Precyzja i Czułość. 
\begin{equation}   F1 = \frac{2}{\frac{1}{PPV} + \frac{1}{TPR}} \end{equation}
\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Klasyfikacja z użyciem metryk i miar podobieństwa tekstów}

W procesie klasyfikacji możliwe jest wykorzystanie jednej z trzech metryk: metryka Euklidesowa, metryka Czebyszewa, metryka Uliczna. Metryki służą obliczeniu odległości pomiędzy dwoma wektora o dowolnym rozmiarze.\\\\ Metryka Eukliedesowa\cite{dane} jest opisana wzorem: 
\begin{equation} d(x, y) = \sqrt{(y_1 - x_1)^2 + ... + (y_n - x_n)^2}  \end{equation}
gdzie: d(x, y) - odległość pomiędzy wektorem x i y; x, y - wektory o tym samym rozmiarze; n - rozmiar wektorów x i y;  x\textsubscript{n}, y\textsubscript{n} - składowe wektora. 
\\\\
Metryka Czebyszewa\cite{dane} jest opisana wzorem: 
\begin{equation} d(x, y) = max(|y_i - x_i|) \end{equation}
gdzie: d(x, y) - odległość pomiędzy wektorem x i y; x, y - wektory o tym samym rozmiarze; n - rozmiar wektorów x i y;  x\textsubscript{i}, y\textsubscript{i} - i-ta składowa wektora;
\\\\
Metryka Uliczna\cite{dane} jest opisana wzorem: 
\begin{equation} d(x, y) = \sum_{i = 1}^{n} |x_i - y_i| \end{equation}
gdzie: d(x, y) - odległość pomiędzy wektorem x i y; x, y - wektory o tym samym rozmiarze; n - rozmiar wektorów x i y;  x\textsubscript{n}, y\textsubscript{n} - składowe wektora. 
\\\\
By móc obliczyć odległość pomiędzy wektorami cech zadanych tekstów, należy wcześniej skorzystać z miary podobieństwa tekstu by zamienić cechy o wartościach tekstowych na liczby w wektorach. W programie została zastosowana metoda bigramów\cite{wyklad}. Korzystając z tej metody obliczamy współczynnik podobieństwa tej samej cechy tekstowej dla dwóch tekstów zgodnie ze wzorem:
\begin{equation} s = \frac {1}{N - 1}  \sum_{i = 0}^{N-1}h(i) \end{equation}

Gdzie s - wartość liczbowa będąca podobieństwem cechy tekstowej obu dokumentów zawierająca się w przedziale [0, 1], N - długość dłużej cechy tekstowej z obu dokumentów, h(i) - przyjmuje wartość 1 gdy podciąg zaczynający się od i-tej pozycji w jednej cesze tekstowej dokumentu występuje w cesze tekstowej drugiego dokumentu, w przeciwnym wypadku przyjmuje wartość 0.
\newline


\textbf{Przykład 3.1}\textit{
Dla obliczenia podobieństwa pomiędzy dwoma słowami: 'night', 'nacht' należy najpierw znaleźć dwa zbiory bigramów należących do każdego ze słów - \{ni, ig, gh, ht\},\{na, ac, ch, ht\}.
Jedynym powtarzającym się bigramem jest 'ht'. Podstawiając wartości do wzoru otrzymujemy:
\begin{equation} s = \frac {0 + 0 + 0 + 1}{5 - 1} = \frac{1}{4} \end{equation}
}

Obliczone w ten sposób podobieństwo cechy tekstowej dla dwóch tekstów wykorzystywane jest do obliczenia odległości pomiędzy nimi:

\begin{equation} d = s - 1 \end{equation}

Gdzie d - odległość cechy tekstowej obu dokumentów, s - podobieństwo cechy tekstowej obu dokumentów.





Wstępna klasyfikacja na ograniczonym zbiorze tekstów została przeprowadzona dla trzech różnych zestawów parametrów wejściowych. \newline
Parametry wejściowe dla pierwszej klasyfikacji wstępnej:
 
\begin{table}[h!]
\caption{Parametry wejściowe dla pierwszej wstępnej klasyfikacji. }
\centering
\vspace{0.1cm}
 \begin{tabular}{c c c c}
    \textbf{K} & \textbf{Metryka}   & \textbf{Procent zbioru trenującego}  & \textbf{Wybrane cechy}   \\
\hline
5 & Czebyszewa & 80\% & Wszystkie cechy \\
\end {tabular}
\label {Parametry wejściowe dla pierwszej wstępnej klasyfikacji. }
\end{table}
\newpage

Wstępne wyniki miary Accuracy dla pierwszej klasyfikacji wstępnej:

\begin{table}[h!]
\caption{Wstępne wyniki miary Accuracy dla pierwszej klasyfikacji wstępnej.}
\centering
\vspace{0.1cm}
 \begin{tabular}{c c c c c c}

    \textbf{Liczba tekstów} &  \makecell{\textbf{Liczba poprawnie} \\\textbf{sklasyfikowanych tekstów}}  & \textbf{Accuracy}\\
\hline
394 & 238 & 0,60\\

\end {tabular}
\label {Wstępne wyniki miary Accuracy dla pierwszej klasyfikacji wstępnej.}
\end{table}


Parametry wejściowe dla drugiej klasyfikacji wstępnej:
 
\begin{table}[h!]
\caption{Parametry wejściowe dla drugiej wstępnej klasyfikacji. }
\centering
\vspace{0.1cm}
 \begin{tabular}{c c c c}
    \textbf{K} & \textbf{Metryka}   & \textbf{Procent zbioru trenującego}  & \textbf{Wybrane cechy}   \\
\hline
3 & Euklidesowa & 95\% &  \makecell{1. Lokalizacja \\z tagu \textless Dateline\textgreater \\2. Tytuł \\z tagu \textless Title\textgreater\\3. Najczęściej występująca\\nazwa  kraju\\4.  Zbiór występujących\\słów kluczowych}\\
\end {tabular}
\label {Parametry wejściowe dla drugiej wstępnej klasyfikacji. }
\end{table}

Wstępne wyniki miary Accuracy dla drugiej klasyfikacji wstępnej:

\begin{table}[h!]
\caption{Wstępne wyniki miary Accuracy dla drugiej klasyfikacji wstępnej.}
\centering
\vspace{0.1cm}
 \begin{tabular}{c c c c c c}

    \textbf{Liczba tekstów} &\makecell{\textbf{Liczba poprawnie} \\\textbf{sklasyfikowanych tekstów}} & \textbf{Accuracy}\\
\hline
394 & 383 & 0,97\\

\end {tabular}
\label {Wstępne wyniki miary Accuracy dla drugiej klasyfikacji wstępnej.}
\end{table}


Parametry wejściowe dla trzeciej klasyfikacji wstępnej:
 
\begin{table}[h!]
\caption{Parametry wejściowe dla trzeciej wstępnej klasyfikacji. }
\centering
\vspace{0.1cm}
 \begin{tabular}{c c c c}
    \textbf{K} & \textbf{Metryka}   & \textbf{Procent zbioru trenującego}  & \textbf{Wybrane cechy}   \\
\hline
9 & Uliczna & 73\% &  \makecell{1.  Zbiór występujących\\słów kluczowych \\2.Liczba wystąpień \\słów kluczowych\\3. Nasycenie tekstu \\ilością słów kluczowych\\4. Najczęściej występujące \\słowo kluczowe}\\
\end {tabular}
\label {Parametry wejściowe dla trzeciej wstępnej klasyfikacji. }
\end{table}

Wstępne wyniki miary Accuracy dla trzeciej klasyfikacji wstępnej:

\begin{table}[h!]
\caption{Wstępne wyniki miary Accuracy dla trzeciej klasyfikacji wstępnej.}
\centering
\vspace{0.1cm}
 \begin{tabular}{c c c c c c}

    \textbf{Liczba tekstów} &\makecell{\textbf{Liczba poprawnie} \\\textbf{sklasyfikowanych tekstów}} & \textbf{Accuracy}\\
\hline
394 & 235 & 0,60\\

\end {tabular}
\label {Wstępne wyniki miary Accuracy dla trzeciej klasyfikacji wstępnej.}
\end{table}
\newpage

Najlepsze wyniki zostały uzyskane dla drugiej wstępnej klasyfikacji, w której został ograniczony zbiór cech, wybrane cechy to: kluczowe słowa, liczba kluczowych słów, nasycenie tekstu słowami kluczowymi, najczęściej występujące słowo kluczowe. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Budowa aplikacji}
\subsection{Diagramy UML}

Aplikacja będzie składała się z dwóch modułów: z modułu ekstrakcji cech oraz z modułu klasyfikacji. Moduł ekstrakcji wczytuje pliki z treścią artykułów. Następnie tworzone są obiekty artykułów. Dla każdego obiektu usuwane są słowa ze stop listy oraz kolejno tworzone są wektory cech artykułów. 

\begin{figure}[h!]
 \centering
 \includegraphics[width=14cm]{Ekstrakcja.png}
 \vspace{-0.3cm}
 \caption{Diagram klas modułu ekstrakcji cech. }
 \label{rysunek do eksperymentu 1 wariantu 1}
\end{figure}
\newpage

Moduł klasyfikacji oblicza odległości pomiędzy artykułem zadanym a każdym z artykułów ze zbioru trenującego za pomocą jednej z zadanych metryk \cite{dane} : metryki Euklidesowej, metryki Ulicznej, metryki Czebyszewa. Dla cech zapisanych w postaci tekstowej ich odległość jest obliczana za pomocą podobieństwa kosinusowego. W ten sposób tworzone są pary zawierające artykuł i odleglość od zadanego artykułu. Następnie znajdowanych jest k najbliższych sąsiadów dla zadanego artykułu, gdzie poprzez słowo sąsiad rozumiemy artykuł ze zbioru trenującego. Ostatecznie artykuł jest klasyfikowany do klasy, której obiekty najczęściej wystąpiły wśród k najbliższych sąsiadów. 

\begin{figure}[h!]
 \centering
 \includegraphics[width=14cm]{Klasyfikator.png}
 \vspace{-0.3cm}
 \caption{Diagram klas modułu klasyfikacji. }
 \label{rysunek do eksperymentu 1 wariantu 1}
\end{figure}

\newpage


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Prezentacja wyników, interfejs użytkownika} 

Po uruchomieniu programu użytkownik proszony jest o podanie poprzez konsolę kolejnych parametrów klasyfikacji. Na początku użytkownik podaje wartość parametru k, następnie wybiera jedną z trzech metryk, kolejno podawany jest procent zbioru treningowego w stosunku do zbioru wszystkich tekstów oraz użytkownik może podać cechy tekstów do klasyfikacji. Wybór parametrów w konsoli prezentuje się:

\begin{figure}[h!]
 \centering
 \includegraphics[width=14cm]{Wybor.png}
 \vspace{-0.3cm}
 \caption{Wybór parametrów klasyfikacji przez użytkownika. }
 \label{Wybór parametrów klasyfikacji przez użytkownika. }
\end{figure}

\newpage
Po wprowadzeniu przez użytkownika wszystkich parametrów klasyfikacji, rozpoczynane jest wczytywanie danych oraz wykonanie klasyfikacji. 
\begin{figure}[h!]
 \centering
 \includegraphics[width=14cm]{srodek.png}
 \vspace{-0.3cm}
 \caption{Wczytywanie danych i klasyfikacja.}
 \label{Wczytywanie danych i klasyfikacja.}
\end{figure}




Po wykonanej klasyfikacji na konsoli wyświetlane są obliczone parametry dla poszczególnych klas klasyfikacji oraz wyliczone parametry dla całego zbioru dokumentów. Dla poszczególnych klas klasyfikacji do obliczonych parametrów zaliczamy liczbę tekstów klasy, liczbę poprawnie zaklasyfikowanych tekstów do rozpatrywanej klasy, liczbę tekstów innych klas zaklasfyfikowanych do rozpatrywanej klasy oraz miary jakości: Precision, Recall, F1. 
\begin{figure}[h!]
 \centering
 \includegraphics[width=14cm]{wynik_dla _klasy.png}
 \vspace{-0.3cm}
 \caption{Wynik klasyfikacji dla pojedyńczej klasy klasyfikacji - klasa west-germany.}
 \label{Wynik klasyfikacji.}
\end{figure}

Dla całego zbioru dokumentów do obliczonych parametrów zaliczamy liczbę tekstów testowych, liczbę poprawnie zaklasyfikowanych tekstów oraz miary jakości: Accuracy, Precision, Recall, F1. 
  
\begin{figure}[h!]
 \centering
 \includegraphics[width=14cm]{wynik.png}
 \vspace{-0.3cm}
 \caption{Wynik klasyfikacji dla całego zbioru dokumentów.}
 \label{Wynik klasyfikacji.}
\end{figure}
\newpage

Do uruchomienia programu wymagana jest wersja Javy: 11. 



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Wyniki klasyfikacji dla różnych parametrów wejściowych}
Wyniki kolejnych eksperymentów wg punktów 2.-8. opisu projektu 1.  Wykresy i tabele
obowiązkowe, dokładnie opisane w ,,captions'' (tytułach), konieczny opis osi i
jednostek wykresów oraz kolumn i wierszy tabel.\\ 

{**Ewentualne wyniki realizacji punktu 9. opisu Projektu 1., czyli,,na ocenę 5.0'' i ich porównanie do wyników z
części obowiązkowej**.}\\

\noindent {\bf Sekcja uzupełniona jako efekt zadania Tydzień 05 wg Harmonogramu Zajęć
na WIKAMP KSR.}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Dyskusja, wnioski}

Dokładne interpretacje uzyskanych wyników w zależności od parametrów klasyfikacji
opisanych w punktach 3.-8 opisu Projektu 1. 
Szczególnie istotne są wnioski o charakterze uniwersalnym, istotne dla podobnych zadań. 
Omówić i wyjaśnić napotkane problemy (jeśli były). Każdy wniosek/problem powinien mieć poparcie
w przeprowadzonych eksperymentach (odwołania do konkretnych wyników: wykresów,
tabel). \\
\underline{Dla końcowej oceny jest to najważniejsza sekcja} sprawozdania, gdyż prezentuje poziom
zrozumienia rozwiązywanego problemu.\\

** Możliwości kontynuacji prac w obszarze systemów rozpoznawania, zwłaszcza w kontekście pracy inżynierskiej,
magisterskiej, naukowej, itp. **\\

\noindent {\bf Sekcja uzupełniona jako efekt zadania Tydzień 06 wg Harmonogramu Zajęć
na WIKAMP KSR.}


\section{Braki w realizacji projektu 1.}
Wymienić wg opisu Projektu 1. wszystkie niezrealizowane obowiązkowe elementy projektu, ewentualnie
podać merytoryczne (ale nie czasowe) przyczyny tych braków. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{thebibliography}{0}
\bibitem{dane} R. Tadeusiewicz: Rozpoznawanie obrazów, PWN, Warszawa, 1991.  
\bibitem{niewiadomski08} A. Niewiadomski, Methods for the Linguistic Summarization of Data: Applications of Fuzzy Sets and Their Extensions, Akademicka Oficyna Wydawnicza EXIT, Warszawa, 2008.

\bibitem{wyklad} A. Niewiadomski, ksr-wyklad-2009.pdf, 2009.

\bibitem{tablica} Internet forum. Wikipedia: The Free Encyclopedia, Dostępny w: \url{https://pl.wikipedia.org/wiki/Tablica_pomy%C5%82ek?fbclid=IwAR1yFbhG8HoSicSBnyA43YhpyU0tJiaIpI6ghUdNZvzDhPtMPwAWHtrdPUQ}

\bibitem{teksty} Machine Learning Repository. UCI:, Dostępny w: \url{http://archive.ics.uci.edu/ml/datasets/Reuters-21578+Text+Categorization+Collection}

\end{thebibliography}

Literatura zawiera wyłącznie źródła recenzowane i/lub o potwierdzonej wiarygodności,
możliwe do weryfikacji i cytowane w sprawozdaniu. 
\end{document}



